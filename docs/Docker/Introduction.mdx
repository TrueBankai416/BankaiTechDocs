#### Example 6: macvlan
- **Description**: Allows you to assign a MAC address to a container, making it appear as a physical device on your network. The Docker host's networking can be bypassed.
- **Use Case**: Useful if you require containers to have direct access to an existing network, behaving as though they were physically attached to it. Often used in scenarios where you need to integrate with legacy applications or systems that expect a direct network connection.
```yaml
name: example
services:
  app:
    image: my-app:image
    networks:
      - macvlan-net

  database:
    image: postgres:latest
    networks:
      - macvlan-net

networks:
  macvlan-net:
    driver: macvlan
    driver_opts:
      parent: eth0  # Specifies which host network interface to use
    ipam:
      config:
        - subnet: 192.168.1.0/24  # Should match your physical network's addressing
          gateway: 192.168.1.1    # Typically your router's IP address
```

The configuration above shows:
- `parent: eth0`: Specifies which host network interface the macvlan network should use. This is required as macvlan creates virtual network interfaces linked to a physical network interface.
- `subnet: 192.168.1.0/24`: Defines the IP address range available to containers in this network. This subnet should match your physical network's addressing scheme.
- `gateway: 192.168.1.1`: Specifies the gateway IP address for the network, typically your router's IP address.
#### Example 7: overlay

- **Description**: Enables Docker Swarm services to communicate across multiple Docker hosts. It leverages network encapsulation to allow containers on different hosts to communicate as if they were on the same host.
- **Use Case**: Ideal for Docker Swarm deployments where you need to manage services that span multiple nodes in a cluster.
```yaml
name: example
services:
  app:
    image: my-app:image
    networks:
      - overlay-net
    deploy:
      replicas: 3

  database:
    image: postgres:latest
    networks:
      - overlay-net
    deploy:
      placement:
        constraints:
          - node.role == manager

networks:
  overlay-net:
    driver: overlay
    attachable: true    # Allows standalone containers to attach to this network
    driver_opts:
      encrypted: "true" # Enables encryption for all network traffic
    ipam:
      config:
        - subnet: 10.0.0.0/24
```

The configuration above shows:
- `attachable: true`: Allows standalone containers (not just swarm services) to attach to this network.
- `encrypted: "true"`: Enables encryption for all traffic on this overlay network, providing additional security for container communication across hosts.
- `deploy`: Configuration specific to swarm mode, defining how services should be deployed across the cluster.
- `subnet`: Defines the IP range for containers in this overlay network.

#### Example 8: network_mode: host
Using `host` mode allows the container to share the host's network stack. Thus, the container does not get its own IP-address allocated, and it uses the host's IP and port space. Containers running in host mode offer the best network performance and are useful when a container needs to manage or observe the host's network stack.
```yaml
name: example
services:
  app:
    image: my-app:image
    network_mode: host

  database:
    image: postgres:latest
    network_mode: host
```

#### Example 9: network_mode: none
This mode disables all networking for the container. Essentially, it provides a container with its own network namespace but without a network interface set up within it. This mode is useful for containers that need to run processes in isolation without requiring network access.
```yaml
name: example
services:
  app:
    image: my-app:image
    network_mode: none

  database:
    image: postgres:latest
    network_mode: none
```

#### Example 10: network_mode: service:[service name]

This option allows a container to share the network stack of another container. By specifying the name of another service defined in the same `docker-compose.yml` file, the container inherits the networking configuration of the targeted service. This is useful for closely coupled services that need to share the network stack without being exposed to the wider network.
```yaml
name: example
services:
  web:
    image: nginx:latest
    ports:
      - "80:80"
      - "443:443"
    networks:
      - frontend
      - backend

  app:
    image: my-app:image
    network_mode: "service:web"  # Shares network namespace with web service
    depends_on:
      - web

  monitoring:
    image: prometheus:latest
    network_mode: "service:web"  # Also shares network namespace with web service
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    depends_on:
      - web

networks:
  frontend:
  backend:
```

The configuration above demonstrates:
- A main web service that defines the network configuration
- An application and monitoring service that share the web service's network stack
- All services share:
  - The same IP address
  - Access to ports 80 and 443
  - Connection to both frontend and backend networks
  - DNS resolution and network interfaces

This setup is particularly useful for:
- Implementing sidecars for monitoring, logging, or security
- Service mesh patterns where proxies need to intercept all network traffic
- Debugging network-related issues across multiple services
#### Example 11: container:[container name/id]

Similar to the `service:` option, but instead of specifying a service name, you directly specify a container name or ID. The container using this mode will share the network namespace of the target container, allowing it to use the exact network configurations, including the IP address.
```yaml
name: example
services:
  webapp:
    image: node:latest
    container_name: webapp-1
    ports:
      - "3000:3000"
    networks:
      - app-net
    volumes:
      - ./app:/usr/src/app
    command: npm start

  debugger:
    image: nicolaka/netshoot:latest
    network_mode: "container:webapp-1"  # Shares network namespace with webapp
    command: ["sh", "-c", "tcpdump -i any port 3000"]

  metrics:
    image: prom/node-exporter:latest
    network_mode: "container:webapp-1"  # Also shares network namespace with webapp
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro

networks:
  app-net:
    driver: bridge
```

The configuration above demonstrates:
- A main webapp container with its own network configuration
- A debugging container (netshoot) that can monitor the webapp's network traffic
- A metrics collection container that shares the same network namespace
- All containers share:
  - The same network interfaces
  - Access to port 3000
  - The same IP address
  - Network visibility and DNS resolution

This setup is particularly useful for:
- Network debugging and troubleshooting
- Performance monitoring and analysis
- Security auditing of network traffic
- Adding network-level tooling without modifying the main application

These examples demonstrate the flexibility of Docker Compose in defining and using networks, enabling complex networking setups to be described in a straightforward and declarative manner.

## Docker Storage
Docker offers various storage options to manage the data generated by and used by containers. These storage solutions cater to different requirements for persistence, scalability, sharing among containers, and data backup. Here are the primary Docker storage options, detailing their benefits, use cases, and Docker Compose examples for each.

### Volumes

**Benefits:**
- Volumes are stored in a part of the host filesystem which is managed by Docker (`/var/lib/docker/volumes/` on Linux). They are the preferred mechanism for persisting data generated by and used by Docker containers.
- Completely managed by Docker, independent of the container's lifecycle, meaning data persists even if a container is deleted.
- Supports sharing among multiple containers and services.

**Use Cases:**
- Persisting database storage, ensuring data survival across container rebuilds.
- Sharing configuration files between the host and containers or among multiple containers.

**Example:**
```yaml
name: example
services:
  db:
    image: postgres:latest
    volumes:
      - db-data:/var/lib/postgresql/data

volumes:
  db-data:
```

### Bind Mounts

**Benefits:**
- Bind mounts can be stored anywhere on the host system. They allow for the storage and management of files or directories on the host system.
- Provide more control over the filesystem as they bypass Docker's management of the volume and allow for the direct inclusion of local host paths.
- Useful for development purposes where code on the host needs to be tested in a container environment in real-time.

**Use Cases:**
- Live reloading during development, where code changes on the host need to be immediately reflected in the container.
- Providing access to sensitive configurations that should not be included in images.

**Example:**
```yaml
name: example
services:
  app:
    image: my-nodejs-app
    volumes:
      - type: bind
        source: ./my-app
        target: /usr/src/app
```

### tmpfs Mounts

**Benefits:**
- Mounted directly in the host system’s memory (or swap, depending on system configuration), tmpfs mounts never touch the physical disk. This results in faster read and write times compared to volumes and bind mounts.
- Data stored in a tmpfs mount is temporary and is cleared when the container is stopped, which can be beneficial for sensitive data or cache.

**Use Cases:**
- Storing cache data or session information that needs quick access but does not need to persist after the container stops.
- Handling sensitive information which should not be written to disk to avoid data leakage.

**Example:**
```yaml
name: example
services:
  cache:
    image: redis:alpine
    tmpfs:
      - /data
```
In Docker Compose, adjusting the size of `tmpfs` mounts along with adding other arguments provides you control over the temporary filesystems associated with your services. This allows for optimizing performance and security for containers that need fast, ephemeral storage. Below is an explanation of how to change the `tmpfs` size and include other options in Docker Compose.
:::warning
tmpfs uses memory (RAM) adjust the size as needed. Monitor how much RAM the mount utilizes
:::

#### Changing the `tmpfs` Size

To specify the size of a `tmpfs` mount, you can use the `size` option. The size is set in bytes but can also be expressed in a human-readable manner using units like `k`, `m`, or `g` for kilobytes, megabytes, or gigabytes, respectively.

#### Additional `tmpfs` Options

Apart from setting the size, Docker allows configuring additional parameters for `tmpfs` mounts including:

- **`mode`**: Sets the file mode (permissions) in an octal format. For example, a mode of `700` would restrict access to the owner of the file only.
- **`uid` and `gid`**: Specify the user ID and group ID for the mount, allowing you to control which user or group owns the `tmpfs` mount.

#### Docker Compose Example with `tmpfs` Options

Here's how you can configure a service with a `tmpfs` mount, including changing its size and setting other options in a Docker Compose file:

```yaml
name: example
services:
  my-service:
    image: my-image
    volumes:
      - type: tmpfs
        target: /app/tmp
        tmpfs:
          size: 100000000 # 100 MB
          mode: 1777
          uid: 1000 # User ID
          gid: 1000 # Group ID
```

#### Explanation:

- **`type: tmpfs`**: Specifies the volume type as tmpfs.
- **`target`**: Defines the container path where the tmpfs mount will be located on the containers filesystem.
- **`tmpfs:size`**: Allocates 100MB of space for the tmpfs mount. Adjust the value as needed for your application requirements.
- **`tmpfs:mode`**: Sets the permissions for the tmpfs mount to `1777`, which is similar to the `tmp` directory on UNIX systems, allowing all users to create files but preventing them from deleting or modifying files owned by others.
- **`tmpfs:uid`** and **`tmpfs:gid`**: These options set the ownership of the tmpfs mount. You may need to adjust these values based on your container's user configuration to ensure proper access to the tmpfs mount.

This configuration demonstrates how to effectively use `tmpfs` mounts for temporary storage needs within your Docker containers, optimizing for both performance and security by controlling the size, permissions, and ownership of the tmpfs mount.

### Named Pipes or FIFO

**Benefits:**
- Allows for one-way data flow between the container and the host or between containers. This can be beneficial for processing data streams.
- Limits data to being in transit, not stored, which can be advantageous for streaming data.

**Use Cases:**
- Real-time event processing where data is consumed by a container, processed, and passed on without the need for persistence.
- Logs or metrics collection where data is streamed from the container to a host service for processing or analysis.

**Example:** Docker Compose does not directly support named pipes in its syntax, but you can create them on the host and use them within containers through bind mounts.

These storage options allow Docker to support a wide range of applications, from temporary data processing to persistent data storage, offering flexibility in how data is managed within and across containers.

## Conclusion

Docker has revolutionized how developers build, deploy, and manage applications. By leveraging Docker, teams can focus on building great software without worrying about inconsistencies between development and production environments. Whether you're developing complex applications, deploying microservices, or automating your development pipeline, Docker provides the tools and flexibility needed to streamline these processes.

## Resources:
[Docker Networking Overview](https://docs.docker.com/engine/network/)\
[Docker Storage](https://docs.docker.com/engine/storage/)

<a href="https://www.buymeacoffee.com/BankaiTech"><img src="https://img.buymeacoffee.com/button-api/?text=Buy me a beer&emoji=🍺&slug=BankaiTech&button_colour=FFDD00&font_colour=000000&font_family=Cookie&outline_colour=000000&coffee_colour=ffffff" /></a>
